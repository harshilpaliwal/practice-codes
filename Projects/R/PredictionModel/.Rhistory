#splitting the dataset
splits <- c(rep("train", 10806), rep("validation", 6483), rep("test", 4324))
house_dataset = house_dataset %>% mutate(splits = sample(splits))
training_set <- house_dataset%>%filter(splits == "train")
validation_set <- house_dataset%>%filter(splits == "validaiton")
test_set <- house_dataset%>%filter(splits == "test")
#splitting the dataset using k-fold cross validation method. The value of k is 15.
#playstore <- playstore %>%mutate(KFold = sample(rep(1:15, length.out = nrow(playstore))))
#splitting the dataset
splits <- c(rep("train", 10806), rep("validation", 6483), rep("test", 4324))
house_dataset = house_dataset %>% mutate(splits = sample(splits))
training_set <- house_dataset%>%filter(splits == "train")
validation_set <- house_dataset%>%filter(splits == "validation")
test_set <- house_dataset%>%filter(splits == "test")
#function to generate a linear model and calculate MSE
lm_mse <- function(formula, train_data, valid_data) {
y_name <- as.character(formula)[2]
y_true <- valid_data[[y_name]]
lm_fit <- lm(formula, train_data)
y_pred <- predict(lm_fit, newdata = valid_data)
mean((y_true - y_pred)^2)
}
# R function to generate all formulas up to size n
generate_formulas <- function(p, x_vars, y_var) {
# Input checking
if (p %% 1 != 0)           stop("Input an integer n")
if (p > length(x_vars))    stop("p should be smaller than number of vars")
if (!is.character(x_vars)) stop("x_vars should be a character vector")
if (!is.character(y_var))  stop("y_vars should be character type")
# combn generates all combinations, apply turns them into formula strings
apply(combn(x_vars, p), 2, function(vars) {
paste0(y_var, " ~ ", paste(vars, collapse = " + "))
})
}
x_vars <- colnames(house_dataset)
x_vars <- x_vars[x_vars != "price"]
x_vars <- x_vars[x_vars != "splits"]
y_var <- "price"
formulas_1_pred <- generate_formulas(p = 1, x_vars = x_vars, y_var = y_var)
formulas_2_pred <- generate_formulas(p = 2, x_vars = x_vars, y_var = y_var)
formulas_3_pred <- generate_formulas(p = 3, x_vars = x_vars, y_var = y_var)
formulas_4_pred <- generate_formulas(p = 4, x_vars = x_vars, y_var = y_var)
mses_1 <- rep(1:length(formulas_1_pred))
mses_2 <- rep(1:length(formulas_2_pred))
mses_3 <- rep(1:length(formulas_3_pred))
mses_4 <- rep(1:length(formulas_4_pred))
for(i in 1:length(formulas_1_pred)) {
mses_1[i] <- lm_mse(as.formula(formulas_1_pred[i]), training_set, validation_set)
}
View(house_dataset)
x_vars <- colnames(house_dataset)
x_vars <- x_vars[x_vars != "price"]
x_vars <- x_vars[x_vars != "splits"]
x_vars <- x_vars[x_vars != "date"]
y_var <- "price"
formulas_1_pred <- generate_formulas(p = 1, x_vars = x_vars, y_var = y_var)
formulas_2_pred <- generate_formulas(p = 2, x_vars = x_vars, y_var = y_var)
formulas_3_pred <- generate_formulas(p = 3, x_vars = x_vars, y_var = y_var)
formulas_4_pred <- generate_formulas(p = 4, x_vars = x_vars, y_var = y_var)
mses_1 <- rep(1:length(formulas_1_pred))
mses_2 <- rep(1:length(formulas_2_pred))
mses_3 <- rep(1:length(formulas_3_pred))
mses_4 <- rep(1:length(formulas_4_pred))
for(i in 1:length(formulas_1_pred)) {
mses_1[i] <- lm_mse(as.formula(formulas_1_pred[i]), training_set, validation_set)
}
for(i in 1:length(formulas_2_pred)) {
mses_2[i] <- lm_mse(as.formula(formulas_2_pred[i]), training_set, validation_set)
}
for (i in 1:length(formulas_3_pred)) {
mses_3[i] <- lm_mse(as.formula(formulas_3_pred[i]), training_set, validation_set)
}
for(i in 1:length(formulas_4_pred)) {
mses_4[i] <- lm_mse(as.formula(formulas_4_pred[i]), training_set, validation_set)
}
min(mses_1)
min(mses_2)
min(mses_3)
min(mses_4)
best_one <- formulas_1_pred[which.min(mses_1)]
best_one
best_two <- formulas_2_pred[which.min(mses_2)]
best_two
best_three <- formulas_3_pred[which.min(mses_3)]
best_three
#as the best MSE is obtained using 4 predictors, our formula is:
best_four <- formulas_4_pred[which.min(mses_4)]
best_four
x_vars <- colnames(house_dataset)
x_vars <- x_vars[x_vars != "price"]
x_vars <- x_vars[x_vars != "splits"]
x_vars <- x_vars[x_vars != "date"]
y_var <- "price"
formulas_1_pred <- generate_formulas(p = 1, x_vars = x_vars, y_var = y_var)
formulas_2_pred <- generate_formulas(p = 2, x_vars = x_vars, y_var = y_var)
formulas_3_pred <- generate_formulas(p = 3, x_vars = x_vars, y_var = y_var)
formulas_4_pred <- generate_formulas(p = 10, x_vars = x_vars, y_var = y_var)
mses_1 <- rep(1:length(formulas_1_pred))
mses_2 <- rep(1:length(formulas_2_pred))
mses_3 <- rep(1:length(formulas_3_pred))
mses_4 <- rep(1:length(formulas_4_pred))
for(i in 1:length(formulas_1_pred)) {
mses_1[i] <- lm_mse(as.formula(formulas_1_pred[i]), training_set, validation_set)
}
for(i in 1:length(formulas_2_pred)) {
mses_2[i] <- lm_mse(as.formula(formulas_2_pred[i]), training_set, validation_set)
}
for (i in 1:length(formulas_3_pred)) {
mses_3[i] <- lm_mse(as.formula(formulas_3_pred[i]), training_set, validation_set)
}
for(i in 1:length(formulas_4_pred)) {
mses_4[i] <- lm_mse(as.formula(formulas_4_pred[i]), training_set, validation_set)
}
x_vars <- colnames(house_dataset)
x_vars <- x_vars[x_vars != "price"]
x_vars <- x_vars[x_vars != "splits"]
x_vars <- x_vars[x_vars != "date"]
y_var <- "price"
formulas_1_pred <- generate_formulas(p = 2, x_vars = x_vars, y_var = y_var)
formulas_2_pred <- generate_formulas(p = 3, x_vars = x_vars, y_var = y_var)
formulas_3_pred <- generate_formulas(p = 5, x_vars = x_vars, y_var = y_var)
formulas_4_pred <- generate_formulas(p = 7, x_vars = x_vars, y_var = y_var)
mses_1 <- rep(1:length(formulas_1_pred))
mses_2 <- rep(1:length(formulas_2_pred))
mses_3 <- rep(1:length(formulas_3_pred))
mses_4 <- rep(1:length(formulas_4_pred))
for(i in 1:length(formulas_1_pred)) {
mses_1[i] <- lm_mse(as.formula(formulas_1_pred[i]), training_set, validation_set)
}
for(i in 1:length(formulas_2_pred)) {
mses_2[i] <- lm_mse(as.formula(formulas_2_pred[i]), training_set, validation_set)
}
for (i in 1:length(formulas_3_pred)) {
mses_3[i] <- lm_mse(as.formula(formulas_3_pred[i]), training_set, validation_set)
}
for(i in 1:length(formulas_4_pred)) {
mses_4[i] <- lm_mse(as.formula(formulas_4_pred[i]), training_set, validation_set)
}
x_vars <- colnames(house_dataset)
x_vars <- x_vars[x_vars != "price"]
x_vars <- x_vars[x_vars != "splits"]
x_vars <- x_vars[x_vars != "date"]
y_var <- "price"
formulas_1_pred <- generate_formulas(p = 2, x_vars = x_vars, y_var = y_var)
formulas_2_pred <- generate_formulas(p = 3, x_vars = x_vars, y_var = y_var)
formulas_3_pred <- generate_formulas(p = 5, x_vars = x_vars, y_var = y_var)
formulas_4_pred <- generate_formulas(p = 19, x_vars = x_vars, y_var = y_var)
mses_1 <- rep(1:length(formulas_1_pred))
mses_2 <- rep(1:length(formulas_2_pred))
mses_3 <- rep(1:length(formulas_3_pred))
mses_4 <- rep(1:length(formulas_4_pred))
for(i in 1:length(formulas_1_pred)) {
mses_1[i] <- lm_mse(as.formula(formulas_1_pred[i]), training_set, validation_set)
}
for(i in 1:length(formulas_2_pred)) {
mses_2[i] <- lm_mse(as.formula(formulas_2_pred[i]), training_set, validation_set)
}
for (i in 1:length(formulas_3_pred)) {
mses_3[i] <- lm_mse(as.formula(formulas_3_pred[i]), training_set, validation_set)
}
for(i in 1:length(formulas_4_pred)) {
mses_4[i] <- lm_mse(as.formula(formulas_4_pred[i]), training_set, validation_set)
}
min(mses_1)
min(mses_2)
min(mses_3)
min(mses_4)
best_one <- formulas_1_pred[which.min(mses_1)]
best_one
best_two <- formulas_2_pred[which.min(mses_2)]
best_two
best_three <- formulas_3_pred[which.min(mses_3)]
best_three
#as the best MSE is obtained using 4 predictors, our formula is:
best_four <- formulas_4_pred[which.min(mses_4)]
best_four
x_train <- model.matrix(price ~ ., data = training_set %>% select(-split)) #dot in the formula means all available variables
x_train <- model.matrix(price ~ ., data = training_set %>% select(-split)) #dot in the formula means all available variables
x_train <- model.matrix(price ~ ., data = training_set %>% select(-split)) #dot in the formula means all available variables
x_train <- model.matrix(price ~ ., data = training_set) #dot in the formula means all available variables
x_train <- model.matrix(price ~ ., data = training_set %>% select(-split))[, -1]
x_train <- model.matrix(price ~ ., data = training_set %>% select(-split))[, -1]
x_train <- model.matrix(price ~ ., data = training_set %>% select(-split))
x_train <- model.matrix(price ~ ., data = training_set %>% select(-split))
c_train <- model.matrix(price ~ ., data = training_set %>% select(-split()))
c_train <- model.matrix(price ~ ., data = training_set %>% select(-split))
x_valid <- model.matrix(price ~ ., data = validation_set %>% select(-split))[, -1]
x_valid <- model.matrix(price ~ ., data = validation_set %>% select(-split))[, -1]
x_valid <- model.matrix(price ~ ., data = validation_set %>% select(-split))[, -1]
x_train <- model.matrix(price ~ ., data = training_set %>% select(-split))[, -1]
x_train <- model.matrix(price ~ ., data = training_set %>% select(-split)[, -21])[, -1]
training_set_matrix <- model.matrix(price ~ ., bind_rows(training_set, validation_set)[, -21])[, -1]
test_matrix <- model.matrix(price ~ ., data = test_set %>% select(-split))[, -1]
training_set_matrix <- model.matrix(price ~ ., bind_rows(training_set, validation_set)[, -21])[, -1]
test_matrix <- model.matrix(price ~ ., data = test_set %>% select(-split))[, -1]
training_set_matrix <- model.matrix(price ~ ., bind_rows(training_set, validation_set)[, -21])[, -1]
test_matrix <- model.matrix(price ~ ., data = test_set %>% select(-split))[, -1]
training_set_matrix <- model.matrix(price ~ ., bind_rows(training_set, validation_set)[, -21])[, -1]
test_matrix <- model.matrix(price ~ ., data = test_set %>% select(-split))
training_set_matrix <- model.matrix(price ~ ., bind_rows(training_set, validation_set)[, -21])[, -1]
test_matrix <- model.matrix(price ~ ., data = test_set %>% select(-split)[, -21])[, -1]
training_set_matrix <- model.matrix(price ~ ., bind_rows(training_set, validation_set)[, -21])[, -1]
result_cv <- cv.glmnet(x = x_cv,
y = c(training_set$price, validation_set$price),
nfolds = 15)
training_set_matrix <- model.matrix(price ~ ., bind_rows(training_set, validation_set)[, -21])[, -1]
result_cv <- cv.glmnet(x = x_cv,
y = c(training_set$price, validation_set$price),
nfolds = 15)
library(ISLR)
library(tidyverse)
library(glmnet)
set.seed(45)
library(ISLR)
library(tidyverse)
library(glmnet)
set.seed(45)
training_set_matrix <- model.matrix(price ~ ., bind_rows(training_set, validation_set)[, -21])[, -1]
result_cv <- cv.glmnet(x = x_cv,
y = c(training_set$price, validation_set$price),
nfolds = 15)
training_set_matrix <- model.matrix(price ~ ., bind_rows(training_set, validation_set)[, -21])[, -1]
test_matrix <- model.matrix(price ~ ., data = test_set %>% select(-split))[, -1]
lm_best <- lm(price ~ sqft_living + waterfront + grade + yr_built + lat, training_set)
mse <- function(y_true, y_pred) {
mean((y_pred - y_true)^2)
}
mse(test_set$price, predict(lm_best, newdata = test_set))
tibble(
y_true = test_set$price,
y_pred = predict(lm_best, newdata = test_set)
) %>%
ggplot(aes(x = y_pred, y = y_true)) +
geom_point() +
geom_abline(slope = 1, intercept = 0, lty = 2)
lm_best <- lm(id + bedrooms + bathrooms + sqft_living + sqft_lot + floors + waterfront + view + condition + grade + sqft_above + sqft_basement + yr_built + yr_renovated + zipcode + lat + long + sqft_living15 + sqft_lot15, training_set)
lm_all_vars <- lm(price ~ id + bedrooms + bathrooms + sqft_living + sqft_lot + floors + waterfront + view + condition + grade + sqft_above + sqft_basement + yr_built + yr_renovated + zipcode + lat + long + sqft_living15 + sqft_lot15, training_set)
mse <- function(y_true, y_pred) {
mean((y_pred - y_true)^2)
}
mse(test_set$price, predict(lm_all_vars, newdata = test_set))
tibble(
y_true = test_set$price,
y_pred = predict(lm_all_vars, newdata = test_set)
) %>%
ggplot(aes(x = y_pred, y = y_true)) +
geom_point() +
geom_abline(slope = 1, intercept = 0, lty = 2)
lm_best_vars <- lm(price ~ sqft_living + waterfront + grade + yr_built + lat, training_set)
mse <- function(y_true, y_pred) {
mean((y_pred - y_true)^2)
}
mse(test_set$price, predict(lm_best_vars, newdata = test_set))
tibble(
y_true = test_set$price,
y_pred = predict(lm_best_vars, newdata = test_set)
) %>%
ggplot(aes(x = y_pred, y = y_true)) +
geom_point() +
geom_abline(slope = 1, intercept = 0, lty = 2)
x_train <- model.matrix(Salary ~ ., data = train_set %>% select(-split)) #dot in the formula means all available variables
x_train <- model.matrix(Salary ~ ., data = train_set %>% select(-split)) #dot in the formula means all available variables
x_train <- model.matrix(Salary ~ ., data = training_set %>% select(-split)) #dot in the formula means all available variables
x_train <- model.matrix(Salary ~ ., data = training_set %>% select(-split)) #dot in the formula means all available variables
library(ISLR)
library(tidyverse)
library(glmnet)
set.seed(45)
house_dataset <- read.csv("~/Programming/R/Data Analysis and Visualisation/Assignments/6776566PredictionModel/data/kc_house_data.csv")
library(ISLR)
library(tidyverse)
library(glmnet)
set.seed(45)
library(ISLR)
library(tidyverse)
library(glmnet)
set.seed(45)
#splitting the dataset
splits <- c(rep("train", 10806), rep("validation", 6483), rep("test", 4324))
house_dataset = house_dataset %>% mutate(splits = sample(splits))
training_set <- house_dataset%>%filter(splits == "train")
validation_set <- house_dataset%>%filter(splits == "validation")
test_set <- house_dataset%>%filter(splits == "test")
#function to generate a linear model and calculate MSE
lm_mse <- function(formula, train_data, valid_data) {
y_name <- as.character(formula)[2]
y_true <- valid_data[[y_name]]
lm_fit <- lm(formula, train_data)
y_pred <- predict(lm_fit, newdata = valid_data)
mean((y_true - y_pred)^2)
}
# R function to generate all formulas up to size n
generate_formulas <- function(p, x_vars, y_var) {
# Input checking
if (p %% 1 != 0)           stop("Input an integer n")
if (p > length(x_vars))    stop("p should be smaller than number of vars")
if (!is.character(x_vars)) stop("x_vars should be a character vector")
if (!is.character(y_var))  stop("y_vars should be character type")
# combn generates all combinations, apply turns them into formula strings
apply(combn(x_vars, p), 2, function(vars) {
paste0(y_var, " ~ ", paste(vars, collapse = " + "))
})
}
#function to generate a linear model and calculate MSE
lm_mse <- function(formula, train_data, valid_data) {
y_name <- as.character(formula)[2]
y_true <- valid_data[[y_name]]
lm_fit <- lm(formula, train_data)
y_pred <- predict(lm_fit, newdata = valid_data)
mean((y_true - y_pred)^2)
}
# R function to generate all formulas up to size n
generate_formulas <- function(p, x_vars, y_var) {
if (p %% 1 != 0)           stop("Input an integer n")
if (p > length(x_vars))    stop("p should be smaller than number of vars")
if (!is.character(x_vars)) stop("x_vars should be a character vector")
if (!is.character(y_var))  stop("y_vars should be character type")
apply(combn(x_vars, p), 2, function(vars) {
paste0(y_var, " ~ ", paste(vars, collapse = " + "))
})
}
x_vars <- colnames(house_dataset)
x_vars <- x_vars[x_vars != "price"]
x_vars <- x_vars[x_vars != "splits"]
x_vars <- x_vars[x_vars != "date"]
y_var <- "price"
formulas_1_pred <- generate_formulas(p = 2, x_vars = x_vars, y_var = y_var)
formulas_2_pred <- generate_formulas(p = 3, x_vars = x_vars, y_var = y_var)
formulas_3_pred <- generate_formulas(p = 5, x_vars = x_vars, y_var = y_var)
formulas_4_pred <- generate_formulas(p = 19, x_vars = x_vars, y_var = y_var)
mses_1 <- rep(1:length(formulas_1_pred))
mses_2 <- rep(1:length(formulas_2_pred))
mses_3 <- rep(1:length(formulas_3_pred))
mses_4 <- rep(1:length(formulas_4_pred))
for(i in 1:length(formulas_1_pred)) {
mses_1[i] <- lm_mse(as.formula(formulas_1_pred[i]), training_set, validation_set)
}
for(i in 1:length(formulas_2_pred)) {
mses_2[i] <- lm_mse(as.formula(formulas_2_pred[i]), training_set, validation_set)
}
for (i in 1:length(formulas_3_pred)) {
mses_3[i] <- lm_mse(as.formula(formulas_3_pred[i]), training_set, validation_set)
}
for(i in 1:length(formulas_4_pred)) {
mses_4[i] <- lm_mse(as.formula(formulas_4_pred[i]), training_set, validation_set)
}
min(mses_1)
min(mses_2)
min(mses_3)
min(mses_4)
best_one <- formulas_1_pred[which.min(mses_1)]
best_one
best_two <- formulas_2_pred[which.min(mses_2)]
best_two
best_three <- formulas_3_pred[which.min(mses_3)]
best_three
best_four <- formulas_4_pred[which.min(mses_4)]
best_four
lm_all_vars <- lm(price ~ id + bedrooms + bathrooms + sqft_living + sqft_lot + floors + waterfront + view + condition + grade + sqft_above + sqft_basement + yr_built + yr_renovated + zipcode + lat + long + sqft_living15 + sqft_lot15, training_set)
mse <- function(y_true, y_pred) {
mean((y_pred - y_true)^2)
}
mse(test_set$price, predict(lm_all_vars, newdata = test_set))
tibble(
y_true = test_set$price,
y_pred = predict(lm_all_vars, newdata = test_set)
) %>%
ggplot(aes(x = y_pred, y = y_true)) +
ggtitle("Plot comparing the true and predicted values of Price of the house. Linear Model uses all the predictors") +
geom_point() +
geom_abline(slope = 1, intercept = 0, lty = 2)
lm_best_vars <- lm(price ~ sqft_living + waterfront + grade + yr_built + lat, training_set)
mse <- function(y_true, y_pred) {
mean((y_pred - y_true)^2)
}
mse(test_set$price, predict(lm_best_vars, newdata = test_set))
tibble(
y_true = test_set$price,
y_pred = predict(lm_best_vars, newdata = test_set)
) %>%
ggplot(aes(x = y_pred, y = y_true)) +
ggtitle("Plot comparing the true and predicted values of Price of the house. Linear Model uses 5 best predictors") +
geom_point() +
geom_abline(slope = 1, intercept = 0, lty = 2)
#we are now trying to create another model using glmnet
x_train <- model.matrix(price ~ ., data = training_set %>% select(-splits))
x_valid <- model.matrix(price ~ ., data = validation_set %>% select(-splits))[, -1]
#Tring to find the best lamba(penalty) for our model
x_cv <- model.matrix(price ~ ., bind_rows(training_set, validation_set)[, -21])[, -1]
result_cv <- cv.glmnet(x = x_cv,
y = c(training_set$price, validation_set$price),
nfolds = 15)
best_lambda <- result_cv$lambda.min
best_lambda
#plotting the lambda values
plot(result_cv)
#we will now use the best lamba on the test set to get our results(Salary)
x_test <- model.matrix(price ~ ., data = training_set %>% select(-splits))[, -1]
y_pred <- as.numeric(predict(result_cv, newx = x_test, s = best_lambda))
tibble(predictedPrice = y_pred,
observedPrice = training_set$price) %>%
ggplot(aes(x = predictedPrice, y = observedPrice)) +
ggtitle("Plot comparing the true and predicted values of Price of the house. Linear Model uses best penalty for improvement.") +
geom_abline(slope = 1, intercept = 0, lty = 2) +
geom_point()
lm_all_vars <- lm(price ~ id + bedrooms + bathrooms + sqft_living + sqft_lot + floors + waterfront + view + condition + grade + sqft_above + sqft_basement + yr_built + yr_renovated + zipcode + lat + long + sqft_living15 + sqft_lot15, training_set)
mse <- function(y_true, y_pred) {
mean((y_pred - y_true)^2)
}
mse_all_vars <- mse(test_set$price, predict(lm_all_vars, newdata = test_set))
tibble(
y_true = test_set$price,
y_pred = predict(lm_all_vars, newdata = test_set)
) %>%
ggplot(aes(x = y_pred, y = y_true)) +
ggtitle("Plot comparing the true and predicted values of Price of the house. Linear Model uses all the predictors") +
geom_point() +
geom_abline(slope = 1, intercept = 0, lty = 2)
lm_best_vars <- lm(price ~ sqft_living + waterfront + grade + yr_built + lat, training_set)
mse_best_vars <-mse(test_set$price, predict(lm_best_vars, newdata = test_set))
tibble(
y_true = test_set$price,
y_pred = predict(lm_best_vars, newdata = test_set)
) %>%
ggplot(aes(x = y_pred, y = y_true)) +
ggtitle("Plot comparing the true and predicted values of Price of the house. Linear Model uses 5 best predictors") +
geom_point() +
geom_abline(slope = 1, intercept = 0, lty = 2)
#we are now trying to create another model using glmnet
x_train <- model.matrix(price ~ ., data = training_set %>% select(-splits))
x_valid <- model.matrix(price ~ ., data = validation_set %>% select(-splits))[, -1]
#Tring to find the best lamba(penalty) for our model
x_cv <- model.matrix(price ~ ., bind_rows(training_set, validation_set)[, -21])[, -1]
result_cv <- cv.glmnet(x = x_cv,
y = c(training_set$price, validation_set$price),
nfolds = 15)
best_lambda <- result_cv$lambda.min
best_lambda
#plotting the lambda values
plot(result_cv)
#we will now use the best lamba on the test set to get our results(Salary)
x_test <- model.matrix(price ~ ., data = training_set %>% select(-splits))[, -1]
y_pred <- as.numeric(predict(result_cv, newx = x_test, s = best_lambda))
tibble(predictedPrice = y_pred,
observedPrice = test_set$price) %>%
ggplot(aes(x = predictedPrice, y = observedPrice)) +
ggtitle("Plot comparing the true and predicted values of Price of the house. Linear Model uses best penalty for improvement.") +
geom_abline(slope = 1, intercept = 0, lty = 2) +
geom_point()
#we are now trying to create another model using glmnet
x_train <- model.matrix(price ~ ., data = training_set %>% select(-splits))
x_valid <- model.matrix(price ~ ., data = validation_set %>% select(-splits))[, -1]
#Tring to find the best lamba(penalty) for our model
x_cv <- model.matrix(price ~ ., bind_rows(training_set, validation_set)[, -21])[, -1]
result_cv <- cv.glmnet(x = x_cv,
y = c(training_set$price, validation_set$price),
nfolds = 15)
#we are now trying to create another model using glmnet
x_train <- model.matrix(price ~ ., data = training_set %>% select(-splits))
x_valid <- model.matrix(price ~ ., data = validation_set %>% select(-splits))[, -1]
#Tring to find the best lamba(penalty) for our model
x_cv <- model.matrix(price ~ ., bind_rows(training_set, validation_set)[, -21])[, -1]
result_cv <- cv.glmnet(x = x_cv,
y = c(training_set$price, validation_set$price),
nfolds = 15)
best_lambda <- result_cv$lambda.min
best_lambda
#plotting the lambda values
plot(result_cv)
#we will now use the best lamba on the test set to get our results(Salary)
x_test <- model.matrix(price ~ ., data = test_set %>% select(-splits))[, -1]
y_pred <- as.numeric(predict(result_cv, newx = x_test, s = best_lambda))
tibble(predictedPrice = y_pred,
observedPrice = test_set$price) %>%
ggplot(aes(x = predictedPrice, y = observedPrice)) +
ggtitle("Plot comparing the true and predicted values of Price of the house. Linear Model uses best penalty for improvement.") +
geom_abline(slope = 1, intercept = 0, lty = 2) +
geom_point()
mse_best_lambda <- mse(test_set$price, y_pred)
#At this point we have three linear models:
# 1. Linear model with best variable
# 2. Linear model with all the variable
# 3. Linear model using the penalty
#Let's now asses how the MSE of each graph compares against the other
mse_all <- c(mse_best_vars, mse_all_vars, mse_best_lambda)
tibble(LinearModel = as.factor(c("Best Predictors", "All Predictors", "Best Penalty")),
MSE = mse_all) %>%
ggplot(aes(x = LinearModel, y = MSE, fill = LinearModel)) +
geom_bar(stat = "identity", col = "black") +
labs(title = "Comparison of test set MSE for different prediction methods") +
theme(legend.position = "none")
#we are now trying to create another model using glmnet
x_train <- model.matrix(price ~ ., data = training_set %>% select(-splits))
x_valid <- model.matrix(price ~ ., data = validation_set %>% select(-splits))[, -1]
#Tring to find the best lamba(penalty) for our model
x_cv <- model.matrix(price ~ ., bind_rows(training_set, validation_set)[, -21])[, -1]
result_cv <- cv.glmnet(x = x_cv,
y = c(training_set$price, validation_set$price),
nfolds = 15)
best_lambda <- result_cv$lambda.min
best_lambda
#plotting the lambda values
plot(result_cv)
#we will now use the best lamba on the test set to get our results(Salary)
x_test <- model.matrix(price ~ ., data = test_set %>% select(-splits))[, -1]
y_pred <- as.numeric(predict(result_cv, newx = x_test, s = best_lambda))
tibble(predictedPrice = y_pred,
observedPrice = test_set$price) %>%
ggplot(aes(x = predictedPrice, y = observedPrice)) +
ggtitle("Plot comparing the true and predicted values of Price of the house. Linear Model uses best penalty for improvement.") +
geom_abline(slope = 1, intercept = 0, lty = 2) +
geom_point()
