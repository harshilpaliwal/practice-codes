# -*- coding: utf-8 -*-
"""EmbeddingsComparison.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1x7zPM1OjxnuGeiSAm1Wd0xosEV9dks2o
"""

!pip install tiny-tokenizer

!pip install flair

!pip install allennlp

import numpy as np
import pandas as pd
from flair.embeddings import Sentence
from flair.embeddings import FlairEmbeddings, BertEmbeddings, ELMoEmbeddings
from flair.embeddings import DocumentPoolEmbeddings
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import f1_score
from google.colab import files
from datetime import datetime

bert_embedding = BertEmbeddings()
bert_train_document_embeddings = DocumentPoolEmbeddings([bert_embedding])
bert_test_document_embeddings = DocumentPoolEmbeddings([bert_embedding])

#requires allennlp
elmo_embedding = ELMoEmbeddings()
elmo_train_document_embeddings = DocumentPoolEmbeddings([elmo_embedding])
elmo_test_document_embeddings = DocumentPoolEmbeddings([elmo_embedding])

flair_embedding_forward = FlairEmbeddings('news-forward')
flair_train_document_embeddings = DocumentPoolEmbeddings([flair_embedding_forward])
flair_test_document_embeddings = DocumentPoolEmbeddings([flair_embedding_forward])

uploaded = files.upload()

data = pd.read_csv("finalDataset.csv")

# BERT

for count in range (30):
  start_time = datetime.now()
  train_sentences = []
  train_labels = []
  test_sentences = []
  test_labels = []
  for row in data.itertuples():
    count_id = int(row.no)
    sentence = Sentence(row.text)
    label = row.label
    if count_id == count:
      test_sentences.append(sentence)
      test_labels.append(label)
    else:
      train_sentences.append(sentence)
      train_labels.append(label)

  #Training Embeddings:
  train_embeddings = []
  # since processing requires some memory we provide sentences into the document embedder in batches (small parts)
  for n in range(0, 5000, 250):  
    sents = train_sentences[n:n+250]
    bert_train_document_embeddings.embed(sents)
    train_embeddings += [np.array(sentence.get_embedding().detach()) for sentence in sents]

  #Test Embeddings:
  test_embeddings = []
  for n in range(0, 5000, 250):  
    sents = test_sentences[n:n+250]
    bert_test_document_embeddings.embed(sents)
    test_embeddings += [np.array(sentence.get_embedding().detach()) for sentence in sents]

  clf_b = DecisionTreeClassifier(max_depth=5, random_state=0)
  clf_b.fit(train_embeddings[:5000], train_labels[:5000])

  predicted_labels = clf_b.predict(test_embeddings[0:5000])
  end_time = datetime.now()
  
  print('Bert - round', count+1, ': Accuracy =',
        accuracy_score(predicted_labels[0:len(test_labels)], test_labels[0:len(test_labels)]),
        '\t F1 =', f1_score(predicted_labels[0:len(test_labels)], test_labels[0:len(test_labels)],
                           average='weighted',labels=np.unique(predicted_labels)),
         '\t Time =', end_time-start_time)

print('**********************************************************************')

# ELMo

for count in range (30):
  start_time = datetime.now()
  train_sentences = []
  train_labels = []
  test_sentences = []
  test_labels = []
  for row in data.itertuples():
    count_id = int(row.no)
    sentence = Sentence(row.text)
    label = row.label
    if count_id == count:
      test_sentences.append(sentence)
      test_labels.append(label)
    else:
      train_sentences.append(sentence)
      train_labels.append(label)

  #Training Embeddings:
  train_embeddings = []
  # since processing requires some memory we provide sentences into the document embedder in batches (small parts)
  for n in range(0, 5000, 250):  
    sents = train_sentences[n:n+250]
    elmo_train_document_embeddings.embed(sents)
    train_embeddings += [np.array(sentence.get_embedding().detach()) for sentence in sents]

  #Test Embeddings:
  test_embeddings = []
  for n in range(0, 5000, 250):  
    sents = test_sentences[n:n+250]
    elmo_test_document_embeddings.embed(sents)
    test_embeddings += [np.array(sentence.get_embedding().detach()) for sentence in sents]

  clf_f = DecisionTreeClassifier(max_depth=5, random_state=0)
  clf_f.fit(train_embeddings[:5000], train_labels[:5000])

  predicted_labels = clf_f.predict(test_embeddings[0:5000])
  end_time = datetime.now()
  print('ELMo - round', count+1, ': Accuracy =',
        accuracy_score(predicted_labels[0:len(test_labels)], test_labels[0:len(test_labels)]),
        '\t F1 =', f1_score(predicted_labels[0:len(test_labels)], test_labels[0:len(test_labels)],
                           average='weighted',labels=np.unique(predicted_labels)),
         '\t Time =', end_time-start_time)
  print('**********************************************************************')

  # Flair

for count in range (30):
  start_time = datetime.now()
  train_sentences = []
  train_labels = []
  test_sentences = []
  test_labels = []
  for row in data.itertuples():
    count_id = int(row.no)
    sentence = Sentence(row.text)
    label = row.label
    if count_id == count:
      test_sentences.append(sentence)
      test_labels.append(label)
    else:
      train_sentences.append(sentence)
      train_labels.append(label)

  #Training Embeddings:
  train_embeddings = []
  # since processing requires some memory we provide sentences into the document embedder in batches (small parts)
  for n in range(0, 5000, 250):  
    sents = train_sentences[n:n+250]
    flair_train_document_embeddings.embed(sents)
    train_embeddings += [np.array(sentence.get_embedding().detach()) for sentence in sents]

  #Test Embeddings:
  test_embeddings = []
  for n in range(0, 5000, 250):  
    sents = test_sentences[n:n+250]
    flair_test_document_embeddings.embed(sents)
    test_embeddings += [np.array(sentence.get_embedding().detach()) for sentence in sents]

  clf_f = DecisionTreeClassifier(max_depth=5, random_state=0)
  clf_f.fit(train_embeddings[:5000], train_labels[:5000])

  predicted_labels = clf_f.predict(test_embeddings[0:5000])
  end_time = datetime.now()
  print('Flair - round', count+1, ': Accuracy =',
        accuracy_score(predicted_labels[0:len(test_labels)], test_labels[0:len(test_labels)]),
        '\t F1 =', f1_score(predicted_labels[0:len(test_labels)], test_labels[0:len(test_labels)],
                           average='weighted',labels=np.unique(predicted_labels)),
         '\t Time =', end_time-start_time)
  
  print('**********************************************************************')